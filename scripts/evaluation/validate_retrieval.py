# scripts/validate_retrieval.py

import os
import sys
from tqdm import tqdm
from ir_core.orchestration.rewriter import QueryRewriter

import hydra
from hydra.core.hydra_config import HydraConfig
from omegaconf import DictConfig, OmegaConf
import wandb

# ------------------------------------

# OmegaConfê°€ ${env:VAR_NAME} êµ¬ë¬¸ì„ í•´ì„í•  ìˆ˜ ìˆë„ë¡ 'env' ë¦¬ì¡¸ë²„ë¥¼ ë“±ë¡í•©ë‹ˆë‹¤.
OmegaConf.register_new_resolver("env", os.getenv)


# Add the src directory to the Python path
def _add_src_to_path():
    scripts_dir = os.path.dirname(__file__)
    repo_dir = os.path.dirname(scripts_dir)
    src_dir = os.path.join(repo_dir, "src")
    if src_dir not in sys.path:
        sys.path.insert(0, src_dir)


from ir_core.utils.wandb import generate_run_name


# --- Hydra ë°ì½”ë ˆì´í„° ì ìš© (Applying the Hydra Decorator) ---
# @hydra.mainì€ ì´ ìŠ¤í¬ë¦½íŠ¸ì˜ ì§„ì…ì ì„ ì •ì˜í•˜ë©°, ì„¤ì • íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
# ì´ì œ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” 'fire' ëŒ€ì‹  Hydraë¥¼ í†µí•´ ì‹¤í–‰ë©ë‹ˆë‹¤.
@hydra.main(config_path="../conf", config_name="config", version_base=None)
def run(cfg: DictConfig) -> None:
    """
    Hydra ì„¤ì •ì„ ì‚¬ìš©í•˜ì—¬ ê²€ì¦ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ì„ í‰ê°€í•˜ê³ ,
    ê·¸ ê²°ê³¼ë¥¼ WandBì— ë¡œê¹…í•©ë‹ˆë‹¤.

    Args:
        cfg (DictConfig): Hydraì— ì˜í•´ ê´€ë¦¬ë˜ëŠ” ì„¤ì • ê°ì²´.
                           conf/config.yaml íŒŒì¼ê³¼ ì»¤ë§¨ë“œë¼ì¸ ì˜¤ë²„ë¼ì´ë“œë¥¼ í†µí•´ ì±„ì›Œì§‘ë‹ˆë‹¤.
    """
    _add_src_to_path()

    # í•„ìš”í•œ ëª¨ë“ˆë“¤ì„ ì§€ì—° ì„í¬íŠ¸í•©ë‹ˆë‹¤.
    from ir_core.config import settings
    from ir_core.generation import get_generator
    from ir_core.orchestration.pipeline import RAGPipeline
    from ir_core.utils import read_jsonl
    from ir_core.evaluation.core import mean_average_precision, average_precision
    from ir_core.analysis.core import RetrievalAnalyzer
    from ir_core.utils.wandb_logger import WandbAnalysisLogger

    # --- WandB ì´ˆê¸°í™” (WandB Initialization) ---
    # OmegaConf.set_structë¥¼ ì‚¬ìš©í•˜ì—¬ cfg ê°ì²´ë¥¼ ì„ì‹œë¡œ ìˆ˜ì • ê°€ëŠ¥í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
    OmegaConf.set_struct(cfg, False)
    # 'validate' ìœ í˜•ì— ë§ëŠ” ì‹¤í–‰ ì´ë¦„ ì ‘ë‘ì‚¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    cfg.wandb.run_name_prefix = cfg.wandb.run_name.validate
    run_name = generate_run_name(cfg)
    OmegaConf.set_struct(cfg, True)  # ë‹¤ì‹œ ì½ê¸° ì „ìš©ìœ¼ë¡œ ë³€ê²½

    wandb.init(
        project=cfg.wandb.project,
        entity=cfg.wandb.entity,
        name=run_name,
        config=OmegaConf.to_container(cfg, resolve=True, throw_on_missing=True),  # type: ignore
        job_type="validation",  # ì‘ì—… ìœ í˜•ì„ 'validation'ìœ¼ë¡œ ì§€ì •
    )

    # ì„¤ì • íŒŒì¼ ê²½ë¡œ ë¡œê¹… (Log Config File Path)
    if hasattr(cfg.wandb, "log_config_path") and cfg.wandb.log_config_path:
        try:
            # Hydraê°€ ì €ì¥í•œ ì„¤ì • íŒŒì¼ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
            config_path = HydraConfig.get().runtime.output_dir
            config_file = os.path.join(config_path, ".hydra", "config.yaml")
            if os.path.exists(config_file):
                print(f"Merged Config File: {config_file}")
                wandb.log({"config_file_path": config_file})
            else:
                print(f"Config file not found at expected location: {config_file}")
        except Exception as e:
            print(f"Could not determine config file path: {e}")

    print("--- ê²€ì¦ ì‹¤í–‰ ì‹œì‘ (Starting Validation Run) ---")
    print(f"ì‚¬ìš©í•  ê²€ì¦ íŒŒì¼: {cfg.data.validation_path}")
    print(f"ì ìš©ëœ ì„¤ì •:\n{OmegaConf.to_yaml(cfg)}")

    # --- ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ (Overriding Settings) ---
    # Hydra ì„¤ì •ì„ ê¸°ì¡´ì˜ ì „ì—­ settings ê°ì²´ì— ë°˜ì˜í•©ë‹ˆë‹¤.
    # ì´ëŠ” íŒŒì´í”„ë¼ì¸ì˜ ë‹¤ë¥¸ ë¶€ë¶„ë“¤ì´ ìµœì‹  íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.
    settings.ALPHA = cfg.model.alpha
    settings.RERANK_K = cfg.model.rerank_k
    print(f"Alpha ê°’ì„ {settings.ALPHA}(ìœ¼)ë¡œ ì˜¤ë²„ë¼ì´ë“œí•©ë‹ˆë‹¤.")
    print(f"Rerank_k ê°’ì„ {settings.RERANK_K}(ìœ¼)ë¡œ ì˜¤ë²„ë¼ì´ë“œí•©ë‹ˆë‹¤.")

    # RAG íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    # ì„¤ì •ì—ì„œ ì§€ì •ëœ ê²½ë¡œì˜ ë„êµ¬ ì„¤ëª… í”„ë¡¬í”„íŠ¸ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    try:
        with open(cfg.prompts.tool_description, "r", encoding="utf-8") as f:
            tool_desc = f.read()
    except FileNotFoundError:
        print(
            f"ì˜¤ë¥˜: '{cfg.prompts.tool_description}'ì—ì„œ ë„êµ¬ ì„¤ëª… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
        return

    # 1. QueryRewriter ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    query_rewriter = QueryRewriter(
        model_name=cfg.pipeline.rewriter_model,
        prompt_template_path=cfg.prompts.rephrase_query,
    )

    # 2. RAG íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•  ë•Œ rewriter ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
    generator = get_generator(cfg)
    pipeline = RAGPipeline(
        generator=generator,
        query_rewriter=query_rewriter,
        tool_prompt_description=tool_desc,
    )

    # ê²€ì¦ ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    try:
        validation_data = list(read_jsonl(cfg.data.validation_path))
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: '{cfg.data.validation_path}'ì—ì„œ ê²€ì¦ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- ìƒ˜í”Œ ì œí•œ ë¡œì§ (Sample Limiting Logic) ---
    # cfg.limit ê°’ì´ ì„¤ì •ëœ ê²½ìš°, ë°ì´í„°ì…‹ì„ í•´ë‹¹ í¬ê¸°ë§Œí¼ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    if cfg.limit:
        print(f"ë°ì´í„°ì…‹ì„ {cfg.limit}ê°œì˜ ìƒ˜í”Œë¡œ ì œí•œí•©ë‹ˆë‹¤.")
        validation_data = validation_data[: cfg.limit]

    # === ANALYSIS FRAMEWORK INTEGRATION ===
    # The new analysis framework will handle all metrics collection and logging

    # === NEW ANALYSIS FRAMEWORK INTEGRATION ===
    # The new analysis framework handles all metrics collection and analysis internally

    # Prepare data for the new analysis framework
    queries_data = []
    retrieval_results_data = []

    for item in tqdm(validation_data, desc="Validating Queries"):
        query = item.get("msg", [{}])[0].get("content")
        ground_truth_id = item.get("ground_truth_doc_id")

        if not query or not ground_truth_id:
            continue

        queries_data.append(
            {"msg": [{"content": query}], "ground_truth_doc_id": ground_truth_id}
        )

        # Get retrieval results for this query
        retrieval_output = pipeline.run_retrieval_only(query)
        retrieval_results_data.append(
            retrieval_output[0] if retrieval_output else {"docs": []}
        )

    # Initialize the new analysis framework
    analyzer = RetrievalAnalyzer(cfg)
    wandb_logger = WandbAnalysisLogger()

    # Perform comprehensive analysis
    analysis_result = analyzer.analyze_batch(
        queries=queries_data, retrieval_results=retrieval_results_data
    )

    # Log results using the enhanced Wandb logger
    wandb_logger.log_analysis_result(result=analysis_result)

    # Update run name with analysis results
    if wandb.run is not None:
        original_name = wandb.run.name
        updated_name = f"{original_name}-MAP_{analysis_result.map_score:.3f}"
        wandb.run.name = updated_name
        print(f"WandB ì‹¤í–‰ ì´ë¦„ ì—…ë°ì´íŠ¸: {original_name} -> {updated_name}")

    print("\n--- ê²€ì¦ ì™„ë£Œ (Validation Complete) ---")
    print(f"ê²€ì¦ëœ ì¿¼ë¦¬ ìˆ˜: {analysis_result.total_queries}")
    print(f"MAP Score: {analysis_result.map_score:.4f}")
    print(f"Retrieval Success Rate: {analysis_result.retrieval_success_rate:.1%}")
    print(f"Rewrite Rate: {analysis_result.rewrite_rate:.1%}")
    print("---------------------------")
    if analysis_result.recommendations:
        print("ğŸ“‹ Recommendations:")
        for rec in analysis_result.recommendations:
            print(f"  â€¢ {rec}")
    print("---------------------------")
    if wandb.run is not None:
        print(f"WandB ì‹¤í–‰ URL: {wandb.run.url}")
    wandb.finish()


if __name__ == "__main__":
    run()
