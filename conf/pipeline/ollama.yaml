# conf/pipeline/ollama.yaml

# =================================================================
# Ollama 파이프라인 모델 설정 (Ollama Pipeline Model Configurations)
# =================================================================

# RAG 파이프라인의 Tool Calling 및 질의 재구성에 사용할 모델
# Note: Currently using OpenAI for tool calling (Ollama doesn't support function calling natively)
# Consider using Ollama with function calling when available, or implement custom tool routing
tool_calling_model: "gpt-3.5-turbo-1106"  # Keep OpenAI for now (function calling required)

# 질의 재구성에 사용할 모델 (더 강력한 모델을 사용할 수 있음)
# Note: Currently using OpenAI for query rewriting (complex reasoning required)
# Could potentially use Ollama with custom prompt engineering
rewriter_model: "gpt-4o-mini"  # Keep OpenAI for now (consistent reasoning required)

# 질의 재구성기 유형 (현재는 openai만 지원)
query_rewriter_type: "openai"  # Keep OpenAI for now

# 최종 답변 생성에 사용할 모델 유형 및 이름
generator_type: "ollama"
generator_model_name: "qwen2:7b"  # Primary Ollama model for answer generation

# 검색 도구(scientific_search)에서 반환할 문서의 기본 개수
default_top_k: 5

