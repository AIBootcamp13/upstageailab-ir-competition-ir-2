# conf/pipeline/ollama-llama.yaml

# =================================================================
# Ollama Llama 파이프라인 모델 설정 (Ollama Llama Pipeline Model Configurations)
# =================================================================

# RAG 파이프라인의 Tool Calling 및 질의 재구성에 사용할 모델
tool_calling_model: "gpt-3.5-turbo-1106"  # Keep OpenAI (function calling required)
rewriter_model: "gpt-4o-mini"            # Keep OpenAI (consistent reasoning required)
query_rewriter_type: "openai"            # Keep OpenAI

# 최종 답변 생성에 사용할 모델 유형 및 이름
generator_type: "ollama"
generator_model_name: "llama3.1:8b"  # Use Llama for potentially better reasoning

# 검색 도구(scientific_search)에서 반환할 문서의 기본 개수
default_top_k: 5
