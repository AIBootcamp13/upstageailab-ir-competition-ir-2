# conf/pipeline/hybrid-ollama.yaml

# =================================================================
# Hybrid Ollama 파이프라인 모델 설정 (Hybrid Ollama Pipeline Model Configurations)
# =================================================================

# RAG 파이프라인의 Tool Calling에 사용할 모델 (Ollama for local OSS tool calling)
tool_calling_model: "llama3.1:8b"  # Ollama (local and OSS)

# 질의 재구성에 사용할 모델 (Ollama for rewriting)
rewriter_model: "llama3.1:8b"               # Ollama for query rewriting
query_rewriter_type: "ollama"            # Use OllamaQueryRewriter

# 질의 재구성기 설정
rewriter:
  max_tokens: 150
  temperature: 0.1

# 최종 답변 생성에 사용할 모델 유형 및 이름
generator_type: "ollama"
generator_model_name: "llama3.1:8b"  # Ollama for answer generation

# 검색 도구(scientific_search)에서 반환할 문서의 기본 개수
default_top_k: 5

# =================================================================
# Implementation Status:
# =================================================================
# ✅ Tool Calling: OpenAI (function calling required)
# ✅ Query Rewriting: Ollama (qwen2:7b) - FIXED!
# ✅ Answer Generation: Ollama (qwen2:7b)
# =================================================================
