# conf/pipeline/hybrid-ollama.yaml

# =================================================================
# Hybrid Ollama 파이프라인 모델 설정 (Hybrid Ollama Pipeline Model Configurations)
# =================================================================

# RAG 파이프라인의 Tool Calling 및 질의 재구성에 사용할 모델
# Note: Using OpenAI for tool calling and rewriting due to:
# - Ollama doesn't have native function calling support
# - Complex reasoning required for query rewriting
# - Consistent behavior across different model architectures
tool_calling_model: "gpt-3.5-turbo-1106"  # OpenAI (function calling required)
rewriter_model: "gpt-4o-mini"            # OpenAI (complex reasoning required)
query_rewriter_type: "openai"            # OpenAI

# 최종 답변 생성에 사용할 모델 유형 및 이름
generator_type: "ollama"
generator_model_name: "qwen2:7b"  # Ollama for answer generation

# 검색 도구(scientific_search)에서 반환할 문서의 기본 개수
default_top_k: 5

# =================================================================
# Future Enhancement Notes:
# =================================================================
# To fully use Ollama for everything, consider:
# 1. Implement custom function calling for Ollama using regex/json parsing
# 2. Create Ollama-based query rewriter with custom prompts
# 3. Use model-specific prompt engineering for consistent behavior
# 4. Consider using llama3.1:8b for better reasoning capabilities
# =================================================================
